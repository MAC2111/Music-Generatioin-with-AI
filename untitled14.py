# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D4d6XUAscJfzryBNMMrKQVC09dSL0y__
"""

# STEP 1: Install required packages
!pip install music21 tensorflow

# STEP 2: Import required libraries
from music21 import instrument, note, stream, chord
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM

# STEP 3: Generate dummy note sequences for simulation (normally, you'd parse MIDI files)
sequence_length = 100
n_patterns = 500

# Create random sequences simulating music patterns
X = np.random.rand(n_patterns, sequence_length, 1)
y = np.random.rand(n_patterns, 1)

# STEP 4: Build the LSTM model
model = Sequential()
model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dropout(0.3))
model.add(LSTM(256))
model.add(Dropout(0.3))
model.add(Dense(1, activation='linear'))

# Compile the model
model.compile(loss='mean_squared_error', optimizer='adam')

# STEP 5: Train the model
model.fit(X, y, epochs=10, batch_size=64)

# STEP 6: Generate a new dummy sequence
generated = model.predict(np.random.rand(1, sequence_length, 1))

# STEP 7: Convert output to music notes (simulation)
output_notes = []

for i in range(10):  # Simulate 10 notes
    new_note = note.Note(int(np.random.randint(60, 72)))  # MIDI note number
    new_note.offset = i
    new_note.storedInstrument = instrument.Piano()
    output_notes.append(new_note)

# STEP 8: Create a music stream and write to MIDI file
midi_stream = stream.Stream(output_notes)
midi_stream.write('midi', fp='generated_music.mid')

# STEP 9: Download the generated MIDI file
from google.colab import files
files.download('generated_music.mid')